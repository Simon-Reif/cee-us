__import__:
    - "experiments/defaults.yaml"
    - "experiments/cee_us/settings/common/basic.yaml"

#training_data_dir: "results/cee_us/construction/2blocks/gnn_ensemble_cee_us_freeplay/checkpoints_225"

train_data_tag: "test_data_tag"
training_data_names: [cee_us_freeplay, planner_flip]
training_data:
  cee_us_freeplay:
    dir: "results/cee_us/construction/2blocks/gnn_ensemble_cee_us_freeplay/checkpoints_225"
    weight: 2.0
    max_episodes: False
  planner_flip:
    dir: "datasets/construction/bc/truncated/flip"
    weight: 1.0
    max_episodes: 1500

#working_dir: "results/cee_us/construction/2blocks/test_buffer_manager"
set_dynamic_work_dir: True
work_dir_prefix: "results/cee_us/construction/2blocks/test_dynamic_dirs"

#load_agent: "results/cee_us/construction/2blocks/cluster_test_main_offline/checkpoint_2900000"
continue_training: false
num_train_steps: 3_000_000
log_every_updates: 10_000
#used in lieu of num_eval_episodes to use gen_rollouts function
number_of_rollouts: 10

debug: true
logging:
  project: "test"
  set_dynamic_wandbname: true
  wandb_name_params: ["disc", "zdim", "mr", "tau", "orth"]
  wandb_name_prefix: "test_name_prefix"
  data_tag_in_name: true


#base env, rollout_params; these settings aren't used
env: "FetchPickAndPlaceConstruction"
env_params:
  sparse: False
  shaped_reward: true
  num_blocks: 2
  stack_only: true
  case: "Singletower"
  visualize_target: true
  visualize_mocap: false
rollout_params:
  render: false
  render_initial: false
  render_eval: false
  record: false
  only_final_reward: false
  use_env_states: true
  logging: true
  task_horizon: 100

controller: "fb"
controller_params:
  compile: false
  cudagraphs: false
  model:
    inference_batch_size: 500_000
    actor_std: 0.2
    norm_obs: true
    norm_with_entire_buffer: true
    seq_length: 1
    archi:
      z_dim: 100
      norm_z: true
      b:
        norm: true
        hidden_dim: 256
        hidden_layers: 2
      f:
        hidden_dim: 1024
        hidden_layers: 1
        model: "simple"  # {'simple', 'residual'}
        embedding_layers: 2
        num_parallel: 2
        ensemble_mode: "batch"  # {'batch', 'seq', 'vmap'}
      actor:
        hidden_dim: 1024
        hidden_layers: 1
        model: "simple"  # {'simple', 'residual'}
        embedding_layers: 2

  train:
    batch_size: 1024
    lr_f: 0.0001
    lr_actor: 0.0001
    lr_b: 0.0001
    ortho_coef: 1
    train_goal_ratio: 0.5
    actor_reg_coef: 0.01
    fb_pessimism_penalty: 0
    actor_pessimism_penalty: 0.5
    discount: 0.98
    weight_decay: 0.0
    clip_grad_norm: 1.0
    stddev_clip: 0.3
    q_loss_coef: 0.0
    fb_target_tau: 0.01
    eps: 1.0e-5


  
eval:
  s_eval:
    num_eval_trajectories: 2
    # gr: last state
    # im: all states
    # im all states and their rewards
    #adaptation_modalities: ["gr", "im10", "rew10", "rew50"]
    adaptation_modalities: ["gr", "im10", "im50", "im"]

  goal_from_exp_data: true
  start_states_from_train_data: true
  where_appl_start_states_expert: true
  #num_eval_episodes: 10 #->number_of_rollouts
  # number of samples to estimate zr
  num_inference_samples: 50_000
  #num_inference_goals: 500
  eval_every_steps: 100_000
  # "Throw" translates into "Slide" in env_params.case
  eval_tasks: ["Flip", "Reach", "PickAndPlace", "Singletower", "Throw"]
  # eval_tasks: ["PickAndPlace", "Singletower", "Throw", "Flip"]


#configs from 
#experiments/cee_us/settings/construction/zero_shot_generalization/common/controller_<task>.yaml
#with num_blocks: 2 for all
eval_envs:
  Reach:
    env: "FetchPickAndPlaceConstruction"
    env_params:
      sparse: false
      shaped_reward: false
      num_blocks: 2
      stack_only: false
      case: "Reach"
      visualize_target: true
      visualize_mocap: false
    rollout_params:
      task_horizon: 100
  PickAndPlace:
    env: "FetchPickAndPlaceConstruction"
    env_params:
      sparse: false
      shaped_reward: false
      num_blocks: 2
      stack_only: false
      case: "PickAndPlace"
      visualize_target: true
      visualize_mocap: false
    rollout_params:
      task_horizon: 400
  Singletower:
    env: "FetchPickAndPlaceConstruction"
    env_params:
      sparse: False
      shaped_reward: true
      num_blocks: 2
      stack_only: true
      case: "Singletower"
      visualize_target: true
      visualize_mocap: false

    rollout_params:
      task_horizon: 600
  # "Slide" stands for "Throw"
  Throw:
    env: "FetchPickAndPlaceConstruction"
    env_params:
      sparse: false
      shaped_reward: false
      num_blocks: 2
      stack_only: true
      case: "Slide"
      visualize_target: true
      visualize_mocap: false
    rollout_params:
      task_horizon: 200
  Flip:
    env: "FetchPickAndPlaceConstruction"
    env_params:
      sparse: true
      shaped_reward: true
      num_blocks: 2
      stack_only: false
      case: "Flip" 
      visualize_mocap: false
    rollout_params:
      task_horizon: 500


  
device: "cuda:0"